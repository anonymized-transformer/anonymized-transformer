<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta http-equiv="Content-Type" content="text/html; charset=windows-1252">

<script src="../files/head.js"></script>

<meta name="viewport" content="width=device-width, initial-scale=1">

<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
</script>

<title>Beam Search Description</title>
<link rel="stylesheet" href="../files/font.css">
<link rel="stylesheet" href="../files/main.css">

<link rel="stylesheet" type="text/css"
    href="https://cdn.rawgit.com/dreampulse/computer-modern-web-font/master/fonts.css">
<style>
body {
  font-family: "Computer Modern Serif", serif;
  font-size: 15pt;
}


* {padding:0;margin:0;box-sizing:border-box;}
#video {
  position: relative;
  padding-bottom: 45%; /* 16:9 */
  height: 0;
}
#video iframe {
  position: absolute;
  top: 0;
  left: 0;
  width: 80%;
  height: 100%;
  transform: translateX(12.5%);
}

</style>

  <style type="text/css">/**
 * Style sheet used by new LibX tooltip code
 */

/* We insert a <div> with libx-tooltip style under the body.
 * This will inherit body's style - we can't afford to inherit undesirable 
 * styles and we must redefine what we need.  OTOH, some things, e.g.
 * font-size, might be ok to be inherited to stay within the page's tone.
 */
.libx-tooltip {
    display: none;
    overflow: visible;
    padding: 5px;
    z-index: 100;
    background-color: #eee;
    color: #000;
    font-weight: normal;
    font-style: normal;
    text-align: left;
    border: 2px solid #666;
    border-radius: 5px;
    -webkit-border-radius: 5px;
    -moz-border-radius: 5px;
}

.libx-tooltip p {
    /* override default 1em margin to keep paragraphs inside a tooltip closer together. */
    margin: .2em;
}
</style><style type="text/css">/**
 * Style sheet used by LibX autolinking code
 */
.libx-autolink {
}

</style>

<style>
table, th, td {
  border: 1px solid black;
}
th, td {
  padding: 15px;
}
</style>

</head>

  <body>

    <div class="outercontainer">
      <div class="container">

        <div class="content project_title">
          <br>
          <h2>Beam Search Description</h2>
        </div>

        <br><br>

      <center>
        <img src="images/beam_search_1.png" width="60%">
        <br><br>
      </center>

      <!-- <center> -->
      <b>Description.</b>&nbsp;
      Beam search is a pruned breadth-first search algorithm.
      <!-- We provide a description of the algorithm following that in <a href="https://arxiv.org/abs/2010.02650">Meister et al., 2020</a>. -->
      At each step $t$, beam search constructs a candidate set $\mathcal{C}_t$ consisting of all combinations of length $t-1$ sequences from the previous hypothesis set $Y_{t-1}$ and a single new token $y$ from vocabulary $\mathcal{V}$.
      The $B$ ("beam width") most likely sequences from the candidate set define the updated hypothesis set $Y_t$.
      Following the presentation in <a href="https://arxiv.org/abs/2010.02650">Meister et al., 2020</a>, we have overloaded $\log P_\theta(\cdot \mid \mathbf{x})$ to define the likelihood of a set of sequences in addition to that of a single sequence: $\log P_\theta(Y \mid \mathbf{x}) = \sum_{\mathbf{y} \in Y} \log P_\theta(\mathbf{y} \mid \mathbf{x})$.
      <br><br>
      We use a <b>beam width of $\mathbf{B=256}$</b>. The size of the <b>vocabulary $\mathbf{\mathcal{V}}$ is 100</b>, corresponding to the number of bins used in the <a href="../quantile_implementation/index.html">discretization procedure</a>.$^1$
      <br><br>

      <b>Planning with beam search.</b>&nbsp;
      Algorithm 1 is presented in an abstracted form so as to apply to a generic sequence generation problem.
      To use beam search for control, we use the last $c$ transitions (the "context size") of the current trajectory as input.
      We use a <b>context size of $\mathbf{c=5}$</b>.
      <!-- For example, assuming that $c \ge 1$, at timestep $t=1$: -->
      <!-- $$\mathbf{x} = \mathbf{s}_0 \circ \mathbf{a}_0 \circ r_0 \circ \mathbf{s}_1.$$ -->
      <br><br>
      The algorithm is also written in a way that abstracts away concerns relating to speed or GPU memory.
      In practice, when evaluating the likelihood of a sequence $\log P_\theta(\mathbf{y} \mid \mathbf{x})$, only the final $c \cdot (N + M + 2)$ tokens (accounting for $N$-dim states, $M$-dim actions, and scalar rewards and rewards-to-go) of the sequence are passed as input to the model $P_\theta$.
      <br><br>

      We use a <b>planning horizon of $10$ transitions</b>, corresponding to a generated sequence length of $10 \cdot (N + M + 2)$ tokens.
      For example, for the Hopper benchmark, $T = 10 \cdot (11 + 3 + 2) = 160$.
      <!-- The call to beam search at $t=0$ can then be written as: -->
      <!-- $$\texttt{beam_search}(\mathbf{x} = \mathbf{s}_0, ~\mathcal{V} = \{1, \ldots, 100\}, ~T = 160, ~B = 256).$$ -->
      <br><br>

      <p style="font-size:15px">
      $^1$Because the beam width is larger than the context size, at $t=1$ of Algorithm 1 we can consider all possible tokens in the hypothesis set $Y_1$. At $t=2$, when there are $100^2$ options, we must begin pruning. This is reflected by allowing the size of the hypothesis set to be less than the beam width in line 4: $| Y | \le B$.
      </p>
      <br><br>

      <!-- are When evaluating the likelihood of a sequence, $\log P_\theta(\mathbf{y} \mid \mathbf{x}),  -->
      <!-- trajectory thus far as input sequence $\mathbf{x}$. current state as input sequence $\mathbf{x}$. -->

      <!-- take as an argument a set of sequences instead of a single sequence. -->
      <!-- concatenated with a single token from$\mathbf{} -->
      <!-- Given an initial conditioning sequence $\mathbf{x}$ and a set of  -->
      <!-- Given an input conditioning sequence $\mathbf{x}$ and a vocabulary $\mathbf{V}$ from which to sample, beam search  -->
      <!-- </center> -->

<!--       <center>
        <table style="width:80%">
          <tr>
            <td><b>Beam width</b></td>
            <td>256</td>
          </tr>
          <tr>
            <td><b>Planning horizon</b></td>
            <td>10</td>
          </tr>
          <tr>
            <td><b>Vocabulary size</b></td>
            <td>100</td>
          </tr>
          <tr>
            <td><b>Context size [number of $(\mathbf{s}, \mathbf{a}, r, V)$ tuples]</b></td>
            <td>5</td>
          </tr>
          <tr>
            <td><b>$k_\text{obs}$ [top-k tokens from which observations are sampled]</b></td>
            <td>1</td>
          </tr>
          <tr>
            <td><b>$k_\text{act}$ [top-k tokens from which actions are sampled]</b></td>
            <td>20</td>
          </tr>
        </table>
      </center>

      <br><br>

      Beam width and context size are standard hyperparameters for decoding Transformer language models.
      Planning horizon is a standard trajectory optimization hyperparameter.
      $k_\text{obs}$ and $k_\text{act}$ indicate that actions are sampled from the most likely $20\%$ of action tokens and next observations are decoded greedily conditioned on previous observations and actions.  -->

      </div>
    </div> 

</body>

</html>
